{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOS83uQDoqpkcl7GAXcaH3R"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "installing dependencies"
   ],
   "metadata": {
    "id": "T6AENheqVm2x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorch-lightning\n",
    "!pip install keyboard\n",
    "!pip install colorama"
   ],
   "metadata": {
    "id": "YkMB3VnAVmQi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "From Common.py "
   ],
   "metadata": {
    "id": "vY5LHAx3VbjT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch as T\n",
    "import torch.jit\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "DEVICE = 'cuda:0' if T.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class Conv(pl.LightningModule):\n",
    "    def __init__(self, c1: int, c2: int, act: bool = True, batch: bool = False, **kwargs):\n",
    "        super(Conv, self).__init__()\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.act = act\n",
    "        self.batch = batch\n",
    "        self.to(DEVICE)\n",
    "        self.conv = nn.Conv2d(c1, c2, **kwargs).to(DEVICE)\n",
    "        self.r = nn.LeakyReLU(0.2).to(DEVICE)\n",
    "        self.n = nn.BatchNorm2d(c2).to(DEVICE)\n",
    "\n",
    "    def forward(self, x) -> T.Tensor:\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.batch:\n",
    "            x = self.n(x)\n",
    "        if self.act:\n",
    "            x = self.r(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Neck(pl.LightningModule):\n",
    "    def __init__(self, c1, c2, e=0.5, shortcut=False):\n",
    "        super(Neck, self).__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        self.cv1 = Conv(c1, c_, kernel_size=1, stride=1)\n",
    "        self.cv2 = Conv(c_, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.add = shortcut and c1 == c2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ck = self.cv2(self.cv1(x))\n",
    "\n",
    "        k = x + ck if self.add else ck\n",
    "\n",
    "        return k\n",
    "\n",
    "\n",
    "class C3(pl.LightningModule):\n",
    "    def __init__(self, c1, c2, e=0.5, n=1, shortcut=True):\n",
    "        super(C3, self).__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        self.cv1 = Conv(c1, c_, kernel_size=3, stride=1, padding=1)\n",
    "        self.cv2 = Conv(c1, c_, kernel_size=3, stride=1, padding=1)\n",
    "        self.cv3 = Conv(c_ * 2, c2, kernel_size=3, padding=1)\n",
    "        self.m = nn.Sequential(*(Neck(c_, c_, shortcut=shortcut, e=0.5) for _ in range(n)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cv3(torch.cat((self.m(self.cv2(x)), self.cv1(x)), dim=1))\n",
    "\n",
    "\n",
    "class C4P(C3):\n",
    "    def __init__(self, c, e=0.5, n=1, ct=2):\n",
    "        super(C4P, self).__init__(c1=c, c2=c, e=e, n=n)\n",
    "        self.ct = ct\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.ct):\n",
    "            x = self.cv3(torch.cat((self.m(self.cv2(x)), self.cv1(x)), dim=1)) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class RepConv(pl.LightningModule):\n",
    "    def __init__(self, c, e=0.5, n=3):\n",
    "        super(RepConv, self).__init__()\n",
    "        c_ = int(c * e)\n",
    "        self.layer = nn.ModuleList()\n",
    "        # self.layer.append(\n",
    "        #     *(Conv(c1=c if i == 0 else c_, c2=c_ if i == 0 else c, kernel_size=3, padding=1, stride=1, batch=False)\n",
    "        #       for i in range(n)))\n",
    "        for i in range(n):\n",
    "            self.layer.append(\n",
    "                Conv(c1=c if i == 0 else c_, c2=c_ if i == 0 else c, kernel_size=3, padding=1, stride=1, batch=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        for layer in self.layer:\n",
    "            x = layer.forward(x)\n",
    "        return x_ + x\n",
    "\n",
    "\n",
    "class ConvSc(RepConv):\n",
    "    def __init__(self, c, n=4):\n",
    "        super(ConvSc, self).__init__(c=c, e=1, n=n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = x.detach().clone()\n",
    "        for layer in self.layer:\n",
    "            x = layer(x) + x\n",
    "        return x + x_\n",
    "\n",
    "\n",
    "class ResidualBlock(pl.LightningModule):\n",
    "    def __init__(self, c1, n: int = 4, use_residual: bool = True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.use_residual = use_residual\n",
    "        self.n = n\n",
    "        self.to(DEVICE)\n",
    "        self.layer = nn.ModuleList()\n",
    "\n",
    "        for _ in range(n):\n",
    "            self.layer.append(\n",
    "                nn.Sequential(\n",
    "                    Conv(c1, c1 * 2, act=True, batch=True, stride=1, padding=0, kernel_size=1),\n",
    "                    Conv(c1 * 2, c1, act=True, batch=True, stride=1, padding=1, kernel_size=3)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x) -> T.Tensor:\n",
    "        c = x\n",
    "        for layer in self.layer:\n",
    "            x = layer(x)\n",
    "        return x + c if self.use_residual else x\n",
    "\n",
    "\n",
    "class Detect(pl.LightningModule):\n",
    "    def __init__(self, c1, nc):\n",
    "        super(Detect, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.to(DEVICE)\n",
    "        self.layer = nn.Sequential(\n",
    "            Conv(c1=c1, c2=c1 * 2, act=True, batch=False, kernel_size=1),\n",
    "            Conv(c1=c1 * 2, c2=(5 + self.nc) * 3, kernel_size=1, batch=False, padding=0, stride=1, act=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> T.Tensor:\n",
    "        return self.layer(x).reshape(x.shape[0], 3, self.nc + 5, x.shape[2], x.shape[3]).permute(0, 1, 3, 4, 2)\n",
    "\n",
    "\n",
    "class CV1(pl.LightningModule):\n",
    "    def __init__(self, c1, c2, e=0.5, n=1, shortcut=False, dim=-3):\n",
    "        super(CV1, self).__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        if shortcut:\n",
    "            c2 = c1\n",
    "        self.c = Conv(c1, c_, kernel_size=3, padding=1, stride=1)\n",
    "        self.v = Conv(c1, c_, kernel_size=3, padding=1, stride=1)\n",
    "        self.m = nn.Sequential(\n",
    "            *(Conv(c_ * 2 if i == 0 else c2, c2, kernel_size=3, stride=1, padding=1) for i in range(n)))\n",
    "        self.sh = c1 == c2\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        c = torch.cat((self.c(x), self.v(x)), dim=self.dim)\n",
    "        return self.m(c) if not self.sh else self.m(\n",
    "            torch.cat((self.c(x), self.v(x)), dim=self.dim)) + x\n",
    "\n",
    "\n",
    "class UC1(pl.LightningModule):\n",
    "    def __init__(self, c1, c2, e=0.5, dim=-3):\n",
    "        super(UC1, self).__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        self.c = Conv(c1=c1, c2=c_, kernel_size=1, stride=1)\n",
    "        self.v = Conv(c1=c1, c2=c_, kernel_size=1, stride=1)\n",
    "        self.m = Conv(c1=c_, c2=c2, kernel_size=1, stride=1)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.m(torch.cat((self.c(x), self.v(x)), dim=self.dim))\n",
    "\n",
    "\n",
    "class MP(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(MP, self).__init__()\n",
    "        self.ls = None\n",
    "\n",
    "    def forward(self, x, ls):\n",
    "        ls.append(x)\n",
    "        return ls\n"
   ],
   "metadata": {
    "id": "AET-uLyFVgrD"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "from utils folder"
   ],
   "metadata": {
    "id": "KAj_y4WfWbeF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "from colorama import Fore\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch as T\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import cv2 as cv\n",
    "import keyboard\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patche\n",
    "import random\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def iou_width_height(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        boxes1 (tensor): width and height of the first bounding boxes\n",
    "        boxes2 (tensor): width and height of the second bounding boxes\n",
    "    Returns:\n",
    "        tensor: Intersection over union of the corresponding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    boxes1 = torch.tensor(boxes1)\n",
    "\n",
    "    boxes1 = boxes1.reshape(1, -1)\n",
    "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * \\\n",
    "                   torch.min(\n",
    "                       boxes1[..., 1], boxes2[..., 1]\n",
    "                   )\n",
    "    union = (\n",
    "            boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
    "    )\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Video explanation of this function:\n",
    "    https://youtu.be/XXYG5ZWtjj0\n",
    "    This function calculates intersection over union (iou) given pred boxes\n",
    "    and target boxes.\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    if box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "\n",
    "\n",
    "def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
    "    \"\"\"\n",
    "    Video explanation of this function:\n",
    "    https://youtu.be/YDkjWEN8jNA\n",
    "    Does Non Max Suppression given bboxes\n",
    "    Parameters:\n",
    "        bboxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [class_pred, prob_score, x1, y1, x2, y2]\n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        threshold (float): threshold to remove predicted bboxes (independent of IoU)\n",
    "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "    Returns:\n",
    "        list: bboxes after performing NMS given a specific IoU threshold\n",
    "    \"\"\"\n",
    "\n",
    "    assert type(bboxes) == list\n",
    "\n",
    "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "\n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "\n",
    "        bboxes = [\n",
    "            box\n",
    "            for box in bboxes\n",
    "            if box[0] != chosen_box[0]\n",
    "               or intersection_over_union(\n",
    "                torch.tensor(chosen_box[2:]),\n",
    "                torch.tensor(box[2:]),\n",
    "                box_format=box_format,\n",
    "            )\n",
    "               < iou_threshold\n",
    "        ]\n",
    "\n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "\n",
    "    return bboxes_after_nms\n",
    "\n",
    "\n",
    "def mean_average_precision(\n",
    "        pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Video explanation of this function:\n",
    "    https://youtu.be/FppOzcDvaDI\n",
    "    This function calculates mean average precision (mAP)\n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones\n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "        num_classes (int): number of classes\n",
    "    Returns:\n",
    "        float: mAP value across all classes given a specific IoU threshold\n",
    "    \"\"\"\n",
    "\n",
    "    average_precisions = []\n",
    "\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "        \n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            num_gts = len(ground_truth_img)\n",
    "            best_iou = 0\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3:]),\n",
    "                    torch.tensor(gt[3:]),\n",
    "                    box_format=box_format,\n",
    "                )\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "               \n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "             \n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "      \n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)\n",
    "\n",
    "\n",
    "\n",
    "class LoadObjectDetectorModule(pl.LightningModule):\n",
    "    def __init__(self, path):\n",
    "        super(LoadObjectDetectorModule, self).__init__()\n",
    "        self.path = path\n",
    "        self.model = self.load_mo()\n",
    "\n",
    "    def load_mo(self):\n",
    "        return torch.load(self.path)\n",
    "\n",
    "    def show(self):\n",
    "        print('{:>35}{:>20}'.format('Ran Epochs :', self.model['epoch']))\n",
    "        print('{:>35}{:>20}'.format('Model Load Status :', 'True' if self.model['model'] else 'False'))\n",
    "        print('{:>35}{:>20}'.format('Optim Load Status :', 'True' if self.model['optim'] else 'False'))\n",
    "\n",
    "    def load(self):\n",
    "        return self.model['model'], self.model['optim'], self.model['epoch']\n",
    "\n",
    "\n",
    "\n",
    "def show(array: (np.ndarray, list, tuple)):\n",
    "    while True:\n",
    "        if isinstance(array, list):\n",
    "            array = np.array(array)\n",
    "        if array.shape[0] == 3:\n",
    "            array = array.reshape((array.shape[1], array.shape[2], array.shape[0]))\n",
    "        array = array.astype(np.uint8)\n",
    "        cv.imshow('show function', array)\n",
    "        cv.waitKey(1)\n",
    "        if keyboard.is_pressed('q'):\n",
    "            break\n",
    "\n",
    "cfg = [\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [3, 32, 3, 1, True, True]},\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [32, 64, 3, 2, True, True]},\n",
    "    {'name': 'ResidualBlock',\n",
    "     'attributes': [64, 4, True]},\n",
    "    {'name': 'C3',\n",
    "     'attributes': [64, 128, True, 2, 0.8]},\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [128, 256, 3, 2, True, True]},\n",
    "    {'name': 'ResidualBlock',\n",
    "     'attributes': [256, 2, True]},\n",
    "    {'name': 'RepConv',\n",
    "     'attributes': [256, 1, 2]},\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [256, 384, 3, 2, True, True]},\n",
    "    {'name': 'Detect',\n",
    "     'attributes': [384, 4]},  # Detect\n",
    "    {'name': 'RepConv',\n",
    "     'attributes': [384, 1, 2]},\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [384, 512, 3, 2, True, True]},\n",
    "    {'name': 'Detect',\n",
    "     'attributes': [512, 4]},  # Detect\n",
    "    {'name': 'RepConv',\n",
    "     'attributes': [512, 1, 2]},\n",
    "    {'name': 'Conv',\n",
    "     'attributes': [512, 768, 3, 2, True, True]},\n",
    "    {'name': 'Detect',\n",
    "     'attributes': [768, 4]},  # Detect\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = 'cuda:0' if T.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class DataReader(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, item, train: bool = True):\n",
    "        x, y = [self.x[item], self.y[item]]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class DataLoaderLightning(LightningDataModule):\n",
    "    def __init__(self, path, debug: bool = False, nc: int = 4, val_pers=0.3, batch_size: int = 6, prc: float = 0.3,\n",
    "                 img_shape: int = 416, val_perc: float = 0.9):\n",
    "        super(DataLoaderLightning, self).__init__()\n",
    "        with open(path, 'r') as r:\n",
    "            iw = yaml.full_load(r)\n",
    "        self.debug = debug\n",
    "        self.nc = nc\n",
    "        self.val_pers = val_pers\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.val_perc = val_perc\n",
    "        self.debug = debug\n",
    "        self.prc = prc\n",
    "        self.path_train = os.path.join(os.getcwd(), iw['train'])\n",
    "        self.path_valid = os.path.join(os.getcwd(), iw['valid'])\n",
    "        # self.path_train = iw['train']\n",
    "        # self.path_valid = iw['valid']\n",
    "        # self.path_train = os.path.join('E:/Programming/Python/Ai-Projects/ObjectDetectorModule', iw['train'])\n",
    "        # self.path_valid = os.path.join('E:/Programming/Python/Ai-Projects/ObjectDetectorModule', iw['valid'])\n",
    "        self.nc = nc\n",
    "        self.ti = [t for t in os.listdir(self.path_train) if os.path.exists(os.path.join(self.path_train, t)) and\n",
    "                   t.endswith('.jpg')]\n",
    "        self.vi = [v for v in os.listdir(self.path_valid) if os.path.exists(os.path.join(self.path_valid, v)) and\n",
    "                   v.endswith('.jpg')]\n",
    "        self.s = [13, 26, 52]\n",
    "\n",
    "        np.seterr(all='ignore')\n",
    "        self.total = len(self.ti) if not self.debug else int(len(self.ti) / self.prc)\n",
    "        self.x_train, self.y_train = self.__start__(current=self.ti)\n",
    "        self.x_val, self.y_val = self.__start__(current=self.vi, is_val=True)\n",
    "\n",
    "    def __start__(self, current, is_val: bool = False):\n",
    "        xsl, ysl = [], []\n",
    "        path = self.path_valid if is_val else self.path_train\n",
    "        tm = len(current) if not self.debug else int(len(current) * (self.prc if not is_val else self.val_perc))\n",
    "        print(f\"Loading {tm} Samples\")\n",
    "        for item in range(tm):\n",
    "\n",
    "            with open(f'{path}/{current[item][:-4]}.txt', 'r') as r:\n",
    "                sr = r.readline()\n",
    "\n",
    "            bboxes = np.roll(\n",
    "                np.loadtxt(f'{path}/{current[item][:-4]}.txt', delimiter=\" \", ndmin=2, ), 4,\n",
    "                axis=1).tolist() if len(sr) != 0 else []\n",
    "\n",
    "            targets = [torch.zeros(3, S, S, 5 + self.nc) for S in self.s]\n",
    "            for box in bboxes:\n",
    "                x1, y1, w, h, class_label = box\n",
    "                dpa = torch.zeros(self.nc)\n",
    "\n",
    "                dpa[int(class_label)] = 1\n",
    "                class_label = dpa\n",
    "                has_anchor = [False] * 3\n",
    "                for anchor_idx in range(3):\n",
    "                    scale_idx = torch.div((1e-16 + anchor_idx), other=3)\n",
    "                    scale_idx = int(scale_idx)\n",
    "                    anchor_on_scale = anchor_idx % 3\n",
    "                    S = self.s[scale_idx]\n",
    "                    i, j = int(S * y1), int(S * x1)\n",
    "\n",
    "                    anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n",
    "                    if not anchor_taken and not has_anchor[scale_idx]:\n",
    "                        targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n",
    "                        x_cell, y_cell = S * x1 - j, S * y1 - i\n",
    "\n",
    "                        box_coordinates = torch.tensor(\n",
    "                            [x1 * S, y1 * S, h * S, h * S]\n",
    "                        )\n",
    "                        targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n",
    "                        targets[scale_idx][anchor_on_scale, i, j, 5:] = class_label\n",
    "\n",
    "                        has_anchor[scale_idx] = True\n",
    "\n",
    "            img = Image.open(f'{path}/{current[item][:-4]}.jpg')\n",
    "            to_tensor = lambda ten: torch.from_numpy(ten)\n",
    "            tt = lambda xf: xf.type(T.float64)\n",
    "            tn = lambda xr: xr / 255\n",
    "            ts = lambda xs: xs.reshape((self.img_shape, self.img_shape, 3))\n",
    "            data = img.getdata()\n",
    "            image_pixel = list(list(pixel) for pixel in data)\n",
    "            image_rgb = np.array(image_pixel).reshape((self.img_shape, self.img_shape, 3))\n",
    "            image_bgr = image_rgb[:, :, ::-1]\n",
    "            x = to_tensor(image_rgb)\n",
    "            x = ts(tn(tt(x))).permute(2, 1, 0).reshape(3, self.img_shape, self.img_shape)\n",
    "            if DEVICE == 'cuda:0':\n",
    "                x = x.type(T.cuda.FloatTensor)\n",
    "            else:\n",
    "                x = x.type(T.FloatTensor)\n",
    "            xsl.append(x)\n",
    "            ysl.append(tuple(targets))\n",
    "\n",
    "            sys.stdout.write('\\r Moving Data To Ram Or Gpu %{} remaining '.format(\n",
    "                f\"{((item / tm) * 100):.4f}\"))\n",
    "        sys.stdout.write('\\n')\n",
    "        return xsl, ysl\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        data_train = DataReader(self.x_train, self.y_train)\n",
    "        return DataLoader(data_train, batch_size=self.batch_size, num_workers=6)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        data_val = DataReader(self.x_val, self.y_val)\n",
    "        return DataLoader(data_val, batch_size=self.batch_size, num_workers=6)\n"
   ],
   "metadata": {
    "id": "oy3y34o0WgAi"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "from loss.py\n"
   ],
   "metadata": {
    "id": "imEPURqRWEom"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def iou(box1, box2):\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3],\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3],\n",
    "\n",
    "    intersect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    intersect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    intersect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    intersect_y2 = torch.min(b1_y2, b2_y2)\n",
    "\n",
    "    intersect_area = (intersect_x2 - intersect_x1 + 1) * (intersect_y2 - intersect_y1 + 1)\n",
    "\n",
    "    # union area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    return intersect_area / (b1_area + b2_area - intersect_area + 1e-16)\n",
    "\n",
    "\n",
    "class Loss(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.ac = 1e-16\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.ca = nn.CrossEntropyLoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.to(DEVICE)\n",
    "        self.anc = [\n",
    "            [[10 / 7, 13 / 7], [16 / 7, 30 / 7], [33 / 7, 23 / 7]],\n",
    "            [[30 / 26, 61 / 26, ], [62 / 26, 45 / 26, ], [59 / 26, 119 / 26]],\n",
    "            [[116 / 52, 90 / 52, ], [156 / 52, 198 / 52, ], [373 / 52, 326 / 52],\n",
    "             ]]\n",
    "        self.anc = torch.tensor(self.anc[0] + self.anc[2] + self.anc[2])\n",
    "\n",
    "    def forward(self, x, y, index):\n",
    "        obj = y[..., 0] == 1\n",
    "        no_obj = y[..., 0] == 0\n",
    "        # print(y[obj])\n",
    "        nol = self.bce(\n",
    "            (x[..., 0:1][no_obj]).to(DEVICE), (y[..., 0:1][no_obj].to(DEVICE))\n",
    "        )\n",
    "        # print(self.anc)\n",
    "        # print(self.anc[l * 3:(l * 3) + 3])\n",
    "        anc = self.anc[index:index + 3].reshape(1, 3, 1, 1, 2)\n",
    "        box_pred = torch.cat(\n",
    "            [self.sigmoid(x[..., 1:3]).to(DEVICE), torch.exp(x[..., 3:5]).to(DEVICE) * anc.to(DEVICE)],\n",
    "            dim=-1)\n",
    "        ious = intersection_over_union(box_pred[obj].to(DEVICE), y[..., 1:5][obj].to(DEVICE)).detach()\n",
    "\n",
    "        ol = self.mse(\n",
    "            self.sigmoid(x[..., 0:1][obj]).to(DEVICE), (ious.to(DEVICE) * y[..., 0:1][obj].to(DEVICE))\n",
    "        )\n",
    "\n",
    "        x[..., 1:3] = self.sigmoid(x[..., 1:3])\n",
    "        y[..., 3:5] = torch.log(\n",
    "            (1e-16 + y[..., 3:5])\n",
    "        )\n",
    "\n",
    "        box_loss = self.mse(x[..., 1:5][obj], y[..., 1:5][obj].to(DEVICE))\n",
    "\n",
    "        class_loss = self.bce(\n",
    "            (F.softmax(x[..., 5:][obj], dim=-1).to(DEVICE)), (y[..., 5:][obj].float().to(DEVICE))\n",
    "        )\n",
    "\n",
    "        loss = nol * 1 + box_loss * 1 + ol * 1 + class_loss * 1\n",
    "\n",
    "        return loss\n"
   ],
   "metadata": {
    "id": "D_Z4Oi4YV_bP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Class\n"
   ],
   "metadata": {
    "id": "sgph0OTuXWW4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from colorama import Fore\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, Checkpoint, LearningRateMonitor, ModelCheckpoint, Timer, \\\n",
    "    EarlyStopping\n",
    "import warnings\n",
    "\n",
    "\n",
    "class TrainDi:\n",
    "    def __init__(self):\n",
    "        self.DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def run(self):\n",
    "        return NotImplementedError\n",
    "\n",
    "    def load(self, path):\n",
    "        return NotImplementedError\n",
    "\n",
    "    def jit_save(self):\n",
    "        return NotImplementedError\n",
    "\n",
    "\n",
    "class OldMethodTrain(TrainDi):\n",
    "    def __init__(self, nc: int = 4, cfg_path: str = 'cfg.yaml'):\n",
    "        super(OldMethodTrain, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.cfg_path = cfg_path\n",
    "        self.net = ObjectDetectorModule(nc=nc, cfg_path=cfg_path).to(self.DEVICE)\n",
    "        self.dr = DataReader(yaml_path='data/path.yaml', nc=nc, debug=True)\n",
    "        self.loss = Loss()\n",
    "        self.epochs = 100\n",
    "        self.c_epoch = 0\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=1e-4)\n",
    "        # self.lambda_lr = lambda epoch: 0.65 ** epoch\n",
    "        self.scheduler = torch.optim.lr_scheduler.ConstantLR(self.optimizer, factor=0.1, total_iters=2)\n",
    "        self.grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def white_space(self):\n",
    "        # for idx in range(self.dr.total):\n",
    "        x, y = self.dr.__getitem__(0)\n",
    "        print('-' * 20)\n",
    "\n",
    "        c = torch.tensor(y[0])\n",
    "        print(c.shape, '\\n')\n",
    "\n",
    "        c = torch.tensor(y[1])\n",
    "        print(c.shape, '\\n')\n",
    "\n",
    "        c = torch.tensor(y[2])\n",
    "        print(c.shape, '\\n')\n",
    "        print('-' * 20)\n",
    "\n",
    "    def run(self):\n",
    "        while self.c_epoch <= self.epochs:\n",
    "            fr = True\n",
    "            for idx in range(self.dr.total):\n",
    "                x, y = self.dr.__getitem__(idx)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                x = x.to(self.DEVICE)\n",
    "\n",
    "                tvm = True\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    x = self.net.forward(x)\n",
    "                    y = [torch.unsqueeze(v, 0) for v in y]\n",
    "\n",
    "                    loss = (self.loss(x=x[0], y=y[2], index=0)\n",
    "                            + self.loss(x=x[1], y=y[1], index=3)\n",
    "                            + self.loss(x=x[2], y=y[0], index=6))\n",
    "\n",
    "                acc = None\n",
    "                if fr:\n",
    "                    fr = False\n",
    "                    sys.stdout.write('\\r {}{:>20}/{:<15}{:>15}{:>15}{:>10}'.format(Fore.YELLOW, 'C Ep|', 'Ep|',\n",
    "\n",
    "                                                                                   'class_loss|',\n",
    "                                                                                   'accuracy|',\n",
    "                                                                                   'lr|'))\n",
    "                    print('/n')\n",
    "                if idx != 0:\n",
    "                    sys.stdout.write(\n",
    "                        '\\r {}{:>20}/{:<15}{:>15}{:>15}{:>10}'.format(Fore.YELLOW, f\"{self.c_epoch}\", f\"{self.epochs}\",\n",
    "                                                                      f\"{loss:.5f}|\",\n",
    "                                                                      f\"{None}|\",\n",
    "                                                                      f\"{self.scheduler.get_lr()[0]}\"))\n",
    "                    sys.stdout.flush()\n",
    "                self.grad_scalar.scale(loss).backward()\n",
    "                self.grad_scalar.step(optimizer=self.optimizer)\n",
    "                self.grad_scalar.update()\n",
    "                if idx % 500 == 0:\n",
    "                    model_ckpt = {\n",
    "                        'model': self.net.state_dict(),\n",
    "                        'optim': self.optimizer.state_dict(),\n",
    "                        'optim_scheduler': self.scheduler.state_dict(),\n",
    "                        'epoch': self.c_epoch\n",
    "                    }\n",
    "                    torch.save(model_ckpt, 'model_grad.pt')\n",
    "            # self.scheduler.step()\n",
    "            print('\\n')\n",
    "            self.c_epoch += 1\n",
    "            # if self.c_epoch <= self.epochs:\n",
    "            #     self.jit_save()\n",
    "\n",
    "    def jit_save(self):\n",
    "        model_ckpt = {\n",
    "            'model': self.net.state_dict(),\n",
    "            'optim': self.optimizer.state_dict(),\n",
    "            'optim_scheduler': self.scheduler.state_dict(),\n",
    "            'epoch': self.c_epoch\n",
    "        }\n",
    "        di = torch.randn((1, 3, 416, 416)).to(self.DEVICE)\n",
    "        j = torch.jit.trace(self.net, di, check_trace=False)\n",
    "        s = torch.jit.script(j)\n",
    "        torch.jit.save(s, 'model-jit.pt',\n",
    "                       model_ckpt\n",
    "                       )\n",
    "\n",
    "    def load(self, path):\n",
    "        lod = LoadObjectDetectorModule('model.pt')\n",
    "        m, o, e = lod.load()\n",
    "        self.net.load_state_dict(m)\n",
    "        self.optimizer.load_state_dict(o)\n",
    "        self.c_epoch = e\n",
    "        lod.show()\n",
    "        print('{:>35}{:>20}'.format('Status :', \" Done *\" if m else 'Error !'))\n"
   ],
   "metadata": {
    "id": "dgj9ukpwXXoe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main Module creator:"
   ],
   "metadata": {
    "id": "yyayAiPEYD37"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from colorama import Fore\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class ObjectDetectorModule(pl.LightningModule):\n",
    "    def __init__(self, nc: int = 4, cfg=None):\n",
    "        super(ObjectDetectorModule, self).__init__()\n",
    "        \"\"\"\n",
    "        Nc : Number of Classes\n",
    "        cfg : pass dict version of configs to create module\n",
    "        \"\"\"\n",
    "        if cfg is None:\n",
    "            cfg = {}\n",
    "        self.nc = nc\n",
    "        if isinstance(cfg, str):\n",
    "            with open(cfg, 'r') as r:\n",
    "                self.cfg = yaml.full_load(r)\n",
    "        else:\n",
    "            self.cfg = cfg\n",
    "\n",
    "        self.layers = self.layer_creator()\n",
    "        self.fr = False\n",
    "\n",
    "        self.to(DEVICE)\n",
    "        self.loss = Loss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def layer_creator(self):\n",
    "        layers = nn.ModuleList()\n",
    "        for cfg in self.cfg:\n",
    "            at = cfg['attributes']\n",
    "            if cfg['name'] == 'Conv':\n",
    "                layers.append(Conv(c1=at[0], c2=at[1], kernel_size=at[2], stride=at[3], act=at[4], batch=at[5],\n",
    "                                   padding=1 if at[2] == 3 else 0)).to(DEVICE)\n",
    "            if cfg['name'] == 'ResidualBlock':\n",
    "                layers.append(ResidualBlock(c1=at[0], n=at[1], use_residual=at[2]).to(DEVICE))\n",
    "            if cfg['name'] == 'Detect':\n",
    "                layers.append(Detect(c1=at[0], nc=at[1]).to(DEVICE))\n",
    "            if cfg['name'] == 'UpSample':\n",
    "                layers.appendnn.Upsample(scale_factor=at[0]).to(DEVICE)\n",
    "            if cfg['name'] == 'C3':\n",
    "                layers.append(C3(c1=at[0], c2=at[1], shortcut=at[2], n=at[3], e=at[4]).to(DEVICE))\n",
    "            if cfg['name'] == 'Neck':\n",
    "                layers.append(Neck(c1=at[0], c2=at[1], shortcut=at[2], e=at[3], ).to(DEVICE))\n",
    "            if cfg['name'] == 'C4P':\n",
    "                layers.append(C4P(c=at[0], e=at[1], n=at[2], ct=at[3]).to(DEVICE))\n",
    "            if cfg['name'] == 'MP':\n",
    "                layers.append(MP())\n",
    "            if cfg['name'] == 'UC1':\n",
    "                layers.append(UC1(c1=at[0], c2=at[1], e=at[2], dim=at[3]))\n",
    "            if cfg['name'] == 'CV1':\n",
    "                layers.append(CV1(c1=at[0], c2=at[1], e=at[2], n=at[3], shortcut=at[4]))\n",
    "            if cfg['name'] == 'RepConv':\n",
    "                layers.append(RepConv(c=at[0], e=at[1], n=at[2]))\n",
    "            if cfg['name'] == 'ConvSc':\n",
    "                layers.append(ConvSc(c=at[0], n=at[1]))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    # @torch.jit.script\n",
    "    def size(self):\n",
    "\n",
    "        ps = 0\n",
    "        for name, pr in self.layers.named_parameters():\n",
    "            sz = (pr.numel() * torch.finfo(pr.data.dtype).bits) / (1024 * 10000)\n",
    "            ps += sz\n",
    "            print(\"| {:<30} | {:<25} |\".format(name, f\"{sz} Mb\"))\n",
    "        print('-' * 50)\n",
    "        print(f' TOTAL SIZE  :  {ps} MB')\n",
    "\n",
    "    def forward(self, x):\n",
    "        route = []\n",
    "        bpm = None\n",
    "        dtt = []\n",
    "        vi = 0\n",
    "\n",
    "        for index, layer in enumerate(self.layers):\n",
    "            # print(x.shape, '\\n')\n",
    "            if not isinstance(layer, (nn.Upsample, Detect, MP)):\n",
    "                if self.fr:\n",
    "                    print('{}{:>50} {:>20}   {:>20}'.format(Fore.BLUE,\n",
    "                                                            f'Shape Before RunTime {[l for l in x.shape]}', \"[!]\",\n",
    "                                                            f\"Layer : {vi}\"))\n",
    "                    print('{:>50} {:>20}   {:>20}'.format(f'Pass To {type(layer).__name__}', \"[->]\",\n",
    "                                                          f\"Layer : {vi}\"))\n",
    "                x = layer(x)\n",
    "                if self.fr:\n",
    "                    print('{:>50} {:>20}   {:>20}'.format(f'Shape After  RunTime {[l for l in x.shape]}', \"[*]\",\n",
    "                                                          f\"Layer : {vi}\"))\n",
    "                    print('-' * 100)\n",
    "\n",
    "            if isinstance(layer, MP):\n",
    "                route = layer(x, route)\n",
    "                if self.fr:\n",
    "                    print('{:>50}  {:>20}'.format(f'NOTICE ! add To Route shape {[v for v in x.shape]}',\n",
    "                                                  '! WARNING !'))\n",
    "                    print('-' * 100)\n",
    "            if isinstance(layer, Detect):\n",
    "                if self.fr:\n",
    "                    print('{:>50} {:>20}   {:>20}'.format('Detect Layer on RunTime', '[!]', f\"Layer : {vi}\",\n",
    "                                                          ))\n",
    "                    print('{:>20}'.format('Before Detect Layer : {}'.format(x.shape)))\n",
    "                f = layer(x)\n",
    "                dtt.append(f)\n",
    "                if self.fr:\n",
    "                    print(\n",
    "                        '{:>50} {:>20}   {:>20}'.format(f'Detect Layer Done shape {[v for v in f.shape]}]', '[*]',\n",
    "                                                        f\"Layer : {vi}\"))\n",
    "                    print('-' * 100)\n",
    "            if isinstance(layer, nn.Upsample):\n",
    "                x = layer(x)\n",
    "                if len(route[-1].shape) == 3:\n",
    "                    c = torch.unsqueeze(route[-1], dim=0)\n",
    "                else:\n",
    "                    c = route[-1]\n",
    "                if self.fr:\n",
    "                    print(\"\\n{:>100}\\n\".format(f'Trying to pair x : {x.shape} to residual {route[-1].shape}',\n",
    "                                               ))\n",
    "\n",
    "                if self.fr:\n",
    "                    print('{:>50} {:>20}   {:>20}\\n'.format(f'UpSample Layer {[v for v in x.shape]}]', '[!]',\n",
    "                                                            f\"Layer : {vi}\"))\n",
    "                    print('-' * 100)\n",
    "\n",
    "                x = torch.concat((c, x), dim=1)\n",
    "                if isinstance(route, list):\n",
    "                    route = route.pop(0)\n",
    "\n",
    "            vi += 1\n",
    "        if len(dtt) != 0:\n",
    "            cv = dtt\n",
    "        else:\n",
    "            cv = x\n",
    "        if self.fr:\n",
    "            self.fr = False\n",
    "        return cv\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=1e-4)\n",
    "        lr_lambda = lambda epoch: 0.85 * epoch\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer, lr_lambda\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        x_ = self(x)\n",
    "        loss = (self.loss.forward(x_[0], y[2], 0) + self.loss.forward(x_[1], y[1], 1) + self.loss.forward(x_[2], y[0],\n",
    "                                                                                                          2))\n",
    "        # acc_train_v1 = accuracy(x_[0], target=y[2].int())\n",
    "        # acc_train_v2 = accuracy(x_[1], target=y[1].int())\n",
    "        # acc_train_v3 = accuracy(x_[2], target=y[0].int())\n",
    "        # self.log('train_acc', torch.tensor((acc_train_v1, acc_train_v2, acc_train_v3)), prog_bar=True, on_step=True,\n",
    "        #          on_epoch=True)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True,\n",
    "                 on_epoch=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        x_ = self(x)\n",
    "\n",
    "        loss = (self.loss.forward(x_[0], y[2], 0) + self.loss.forward(x_[1], y[1], 1) + self.loss.forward(x_[2], y[0],\n",
    "                                                                                                          2))\n",
    "        # acc_val_v1 = accuracy(x_[0], target=y[2].int())\n",
    "        # acc_val_v2 = accuracy(x_[1], target=y[1].int())\n",
    "        # acc_val_v3 = accuracy(x_[2], target=y[0].int())\n",
    "        # self.log('val_acc', torch.tensor((acc_val_v1, acc_val_v2, acc_val_v3)), prog_bar=True, on_step=True,\n",
    "        #          on_epoch=True)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=True,\n",
    "                 on_epoch=True)\n",
    "        return {\"loss\": loss}\n"
   ],
   "metadata": {
    "id": "X3KNxMVgYC7f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "main training loop from train.py"
   ],
   "metadata": {
    "id": "qd3epuJZYX_p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, Checkpoint, LearningRateMonitor, ModelCheckpoint, Timer, \\\n",
    "    EarlyStopping\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelSummary\n",
    "\n",
    "cfg_list = cfg\n",
    "\n",
    "class LightningTrain:\n",
    "    def __init__(self, nc: int = 4, cfg: [str, list] = cfg_list):\n",
    "        super(LightningTrain, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.cfg = cfg\n",
    "        self.net = ObjectDetectorModule(cfg=self.cfg, nc=self.nc)\n",
    "\n",
    "    def train(self, time: str = None):\n",
    "        self.net.prepare_data()\n",
    "\n",
    "        backbone_fine = BackboneFinetuning()\n",
    "        checkpoint = Checkpoint()\n",
    "        model_summery = ModelSummary(max_depth=10)\n",
    "        model_checkpoint = ModelCheckpoint(dirpath='model/saves/', save_top_k=10, monitor='train_loss')\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "        early_stopping = EarlyStopping('val_loss')\n",
    "        timer = Timer(duration='01:00:00:00' if time is None else time)\n",
    "        trainer = pl.Trainer(devices=1, accelerator='gpu', min_epochs=50, max_epochs=50000,\n",
    "                             callbacks=[model_summery, model_checkpoint, checkpoint, lr_monitor, early_stopping, timer])\n",
    "        data_loader_lightning = DataLoaderLightning(path='data/path.yaml', debug=True, val_pers=0.3, nc=4, prc=0.2,\n",
    "                                                    batch_size=1)\n",
    "        dataloader_train = data_loader_lightning.train_dataloader()\n",
    "        dataloader_validation = data_loader_lightning.val_dataloader()\n",
    "        trainer.fit(self.net, train_dataloaders=dataloader_train, val_dataloaders=dataloader_validation)\n",
    "        self.net.prepare_data()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_class = LightningTrain()\n",
    "    train_class.train()\n"
   ],
   "metadata": {
    "id": "S2MWrqhbYTXe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ny , nx = torch.arange(30),torch.arange(30)\n",
    "gx,gy = torch.meshgrid((nx,ny),indexing='xy')\n",
    "print(gx.shape)"
   ],
   "metadata": {
    "id": "scVdjDbBYltI"
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 30])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x2552f9a1760>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.axes(projection='3d')\n",
    "z = torch.sin(torch.sqrt(gx * gx + gy * gy))\n",
    "ax.plot_surface(gx.numpy(),gx.numpy(),z.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x = np.arange(640)\n",
    "y = np.arange(640)\n",
    "g = np.asarray([x,y])\n",
    "g = g.transpose()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(640, 2)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "k = KMeans(n_clusters=9)\n",
    "k.fit(g)\n",
    "p = k.predict(g)\n",
    "anch = []\n",
    "for i in range(9):\n",
    "    anch.append(np.mean(g[i==p],axis=0))\n",
    "anch = np.array(anch)\n",
    "anch_c = anch.copy()\n",
    "anch[...,0] = anch_c[...,0] / 640*640\n",
    "anch[...,1] = anch_c[...,1] / 640*640"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[467.5 467.5]\n",
      " [107.5 107.5]\n",
      " [322.  322. ]\n",
      " [605.5 605.5]\n",
      " [395.  395. ]\n",
      " [249.5 249.5]\n",
      " [ 35.5  35.5]\n",
      " [178.5 178.5]\n",
      " [537.5 537.5]]\n"
     ]
    }
   ],
   "source": [
    "print(anch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
