{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOS83uQDoqpkcl7GAXcaH3R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["installing dependencies"],"metadata":{"id":"T6AENheqVm2x"}},{"cell_type":"code","source":["!pip install pytorch-lightning\n","!pip install keyboard\n","!pip install colorama"],"metadata":{"id":"YkMB3VnAVmQi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From Common.py "],"metadata":{"id":"vY5LHAx3VbjT"}},{"cell_type":"code","source":["import torch as T\n","import torch.jit\n","import torch.nn as nn\n","import pytorch_lightning as pl\n","\n","DEVICE = 'cuda:0' if T.cuda.is_available() else 'cpu'\n","\n","\n","class Conv(pl.LightningModule):\n","    def __init__(self, c1: int, c2: int, act: bool = True, batch: bool = False, **kwargs):\n","        super(Conv, self).__init__()\n","        self.c1 = c1\n","        self.c2 = c2\n","        self.act = act\n","        self.batch = batch\n","        self.to(DEVICE)\n","        self.conv = nn.Conv2d(c1, c2, **kwargs).to(DEVICE)\n","        self.r = nn.LeakyReLU(0.2).to(DEVICE)\n","        self.n = nn.BatchNorm2d(c2).to(DEVICE)\n","\n","    def forward(self, x) -> T.Tensor:\n","\n","        x = self.conv(x)\n","        if self.batch:\n","            x = self.n(x)\n","        if self.act:\n","            x = self.r(x)\n","\n","        return x\n","\n","\n","class Neck(pl.LightningModule):\n","    def __init__(self, c1, c2, e=0.5, shortcut=False):\n","        super(Neck, self).__init__()\n","        c_ = int(c2 * e)\n","        self.cv1 = Conv(c1, c_, kernel_size=1, stride=1)\n","        self.cv2 = Conv(c_, c2, kernel_size=3, stride=1, padding=1)\n","        self.add = shortcut and c1 == c2\n","\n","    def forward(self, x):\n","        ck = self.cv2(self.cv1(x))\n","\n","        k = x + ck if self.add else ck\n","\n","        return k\n","\n","\n","class C3(pl.LightningModule):\n","    def __init__(self, c1, c2, e=0.5, n=1, shortcut=True):\n","        super(C3, self).__init__()\n","        c_ = int(c2 * e)\n","        self.cv1 = Conv(c1, c_, kernel_size=3, stride=1, padding=1)\n","        self.cv2 = Conv(c1, c_, kernel_size=3, stride=1, padding=1)\n","        self.cv3 = Conv(c_ * 2, c2, kernel_size=3, padding=1)\n","        self.m = nn.Sequential(*(Neck(c_, c_, shortcut=shortcut, e=0.5) for _ in range(n)))\n","\n","    def forward(self, x):\n","        return self.cv3(torch.cat((self.m(self.cv2(x)), self.cv1(x)), dim=1))\n","\n","\n","class C4P(C3):\n","    def __init__(self, c, e=0.5, n=1, ct=2):\n","        super(C4P, self).__init__(c1=c, c2=c, e=e, n=n)\n","        self.ct = ct\n","\n","    def forward(self, x):\n","        for _ in range(self.ct):\n","            x = self.cv3(torch.cat((self.m(self.cv2(x)), self.cv1(x)), dim=1)) + x\n","        return x\n","\n","\n","class RepConv(pl.LightningModule):\n","    def __init__(self, c, e=0.5, n=3):\n","        super(RepConv, self).__init__()\n","        c_ = int(c * e)\n","        self.layer = nn.ModuleList()\n","        # self.layer.append(\n","        #     *(Conv(c1=c if i == 0 else c_, c2=c_ if i == 0 else c, kernel_size=3, padding=1, stride=1, batch=False)\n","        #       for i in range(n)))\n","        for i in range(n):\n","            self.layer.append(\n","                Conv(c1=c if i == 0 else c_, c2=c_ if i == 0 else c, kernel_size=3, padding=1, stride=1, batch=False))\n","\n","    def forward(self, x):\n","        x_ = x\n","        for layer in self.layer:\n","            x = layer.forward(x)\n","        return x_ + x\n","\n","\n","class ConvSc(RepConv):\n","    def __init__(self, c, n=4):\n","        super(ConvSc, self).__init__(c=c, e=1, n=n)\n","\n","    def forward(self, x):\n","        x_ = x.detach().clone()\n","        for layer in self.layer:\n","            x = layer(x) + x\n","        return x + x_\n","\n","\n","class ResidualBlock(pl.LightningModule):\n","    def __init__(self, c1, n: int = 4, use_residual: bool = True):\n","        super(ResidualBlock, self).__init__()\n","        self.use_residual = use_residual\n","        self.n = n\n","        self.to(DEVICE)\n","        self.layer = nn.ModuleList()\n","\n","        for _ in range(n):\n","            self.layer.append(\n","                nn.Sequential(\n","                    Conv(c1, c1 * 2, act=True, batch=True, stride=1, padding=0, kernel_size=1),\n","                    Conv(c1 * 2, c1, act=True, batch=True, stride=1, padding=1, kernel_size=3)\n","                )\n","            )\n","\n","    def forward(self, x) -> T.Tensor:\n","        c = x\n","        for layer in self.layer:\n","            x = layer(x)\n","        return x + c if self.use_residual else x\n","\n","\n","class Detect(pl.LightningModule):\n","    def __init__(self, c1, nc):\n","        super(Detect, self).__init__()\n","        self.nc = nc\n","        self.to(DEVICE)\n","        self.layer = nn.Sequential(\n","            Conv(c1=c1, c2=c1 * 2, act=True, batch=False, kernel_size=1),\n","            Conv(c1=c1 * 2, c2=(5 + self.nc) * 3, kernel_size=1, batch=False, padding=0, stride=1, act=True)\n","        )\n","\n","    def forward(self, x) -> T.Tensor:\n","        return self.layer(x).reshape(x.shape[0], 3, self.nc + 5, x.shape[2], x.shape[3]).permute(0, 1, 3, 4, 2)\n","\n","\n","class CV1(pl.LightningModule):\n","    def __init__(self, c1, c2, e=0.5, n=1, shortcut=False, dim=-3):\n","        super(CV1, self).__init__()\n","        c_ = int(c2 * e)\n","        if shortcut:\n","            c2 = c1\n","        self.c = Conv(c1, c_, kernel_size=3, padding=1, stride=1)\n","        self.v = Conv(c1, c_, kernel_size=3, padding=1, stride=1)\n","        self.m = nn.Sequential(\n","            *(Conv(c_ * 2 if i == 0 else c2, c2, kernel_size=3, stride=1, padding=1) for i in range(n)))\n","        self.sh = c1 == c2\n","        self.dim = dim\n","\n","    def forward(self, x):\n","        c = torch.cat((self.c(x), self.v(x)), dim=self.dim)\n","        return self.m(c) if not self.sh else self.m(\n","            torch.cat((self.c(x), self.v(x)), dim=self.dim)) + x\n","\n","\n","class UC1(pl.LightningModule):\n","    def __init__(self, c1, c2, e=0.5, dim=-3):\n","        super(UC1, self).__init__()\n","        c_ = int(c2 * e)\n","        self.c = Conv(c1=c1, c2=c_, kernel_size=1, stride=1)\n","        self.v = Conv(c1=c1, c2=c_, kernel_size=1, stride=1)\n","        self.m = Conv(c1=c_, c2=c2, kernel_size=1, stride=1)\n","        self.dim = dim\n","\n","    def forward(self, x):\n","        return self.m(torch.cat((self.c(x), self.v(x)), dim=self.dim))\n","\n","\n","class MP(pl.LightningModule):\n","    def __init__(self):\n","        super(MP, self).__init__()\n","        self.ls = None\n","\n","    def forward(self, x, ls):\n","        ls.append(x)\n","        return ls\n"],"metadata":{"id":"AET-uLyFVgrD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["from utils folder"],"metadata":{"id":"KAj_y4WfWbeF"}},{"cell_type":"code","source":["import yaml\n","from colorama import Fore\n","import os\n","import sys\n","import numpy as np\n","import torch\n","import torch as T\n","import yaml\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_lightning import LightningDataModule\n","import cv2 as cv\n","import keyboard\n","import numpy as np\n","import pytorch_lightning as pl\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patche\n","import random\n","from collections import Counter\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","\n","def iou_width_height(boxes1, boxes2):\n","    \"\"\"\n","    Parameters:\n","        boxes1 (tensor): width and height of the first bounding boxes\n","        boxes2 (tensor): width and height of the second bounding boxes\n","    Returns:\n","        tensor: Intersection over union of the corresponding boxes\n","    \"\"\"\n","\n","    boxes1 = torch.tensor(boxes1)\n","\n","    boxes1 = boxes1.reshape(1, -1)\n","    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * \\\n","                   torch.min(\n","                       boxes1[..., 1], boxes2[..., 1]\n","                   )\n","    union = (\n","            boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n","    )\n","    return intersection / union\n","\n","\n","def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n","    \"\"\"\n","    Video explanation of this function:\n","    https://youtu.be/XXYG5ZWtjj0\n","    This function calculates intersection over union (iou) given pred boxes\n","    and target boxes.\n","    Parameters:\n","        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n","        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n","        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n","    Returns:\n","        tensor: Intersection over union for all examples\n","    \"\"\"\n","\n","    if box_format == \"midpoint\":\n","        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n","        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n","        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n","        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n","        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n","        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n","        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n","        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n","\n","    if box_format == \"corners\":\n","        box1_x1 = boxes_preds[..., 0:1]\n","        box1_y1 = boxes_preds[..., 1:2]\n","        box1_x2 = boxes_preds[..., 2:3]\n","        box1_y2 = boxes_preds[..., 3:4]\n","        box2_x1 = boxes_labels[..., 0:1]\n","        box2_y1 = boxes_labels[..., 1:2]\n","        box2_x2 = boxes_labels[..., 2:3]\n","        box2_y2 = boxes_labels[..., 3:4]\n","\n","    x1 = torch.max(box1_x1, box2_x1)\n","    y1 = torch.max(box1_y1, box2_y1)\n","    x2 = torch.min(box1_x2, box2_x2)\n","    y2 = torch.min(box1_y2, box2_y2)\n","\n","    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n","    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n","\n","    return intersection / (box1_area + box2_area - intersection + 1e-6)\n","\n","\n","def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n","    \"\"\"\n","    Video explanation of this function:\n","    https://youtu.be/YDkjWEN8jNA\n","    Does Non Max Suppression given bboxes\n","    Parameters:\n","        bboxes (list): list of lists containing all bboxes with each bboxes\n","        specified as [class_pred, prob_score, x1, y1, x2, y2]\n","        iou_threshold (float): threshold where predicted bboxes is correct\n","        threshold (float): threshold to remove predicted bboxes (independent of IoU)\n","        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n","    Returns:\n","        list: bboxes after performing NMS given a specific IoU threshold\n","    \"\"\"\n","\n","    assert type(bboxes) == list\n","\n","    bboxes = [box for box in bboxes if box[1] > threshold]\n","    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n","    bboxes_after_nms = []\n","\n","    while bboxes:\n","        chosen_box = bboxes.pop(0)\n","\n","        bboxes = [\n","            box\n","            for box in bboxes\n","            if box[0] != chosen_box[0]\n","               or intersection_over_union(\n","                torch.tensor(chosen_box[2:]),\n","                torch.tensor(box[2:]),\n","                box_format=box_format,\n","            )\n","               < iou_threshold\n","        ]\n","\n","        bboxes_after_nms.append(chosen_box)\n","\n","    return bboxes_after_nms\n","\n","\n","def mean_average_precision(\n","        pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n","):\n","    \"\"\"\n","    Video explanation of this function:\n","    https://youtu.be/FppOzcDvaDI\n","    This function calculates mean average precision (mAP)\n","    Parameters:\n","        pred_boxes (list): list of lists containing all bboxes with each bboxes\n","        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n","        true_boxes (list): Similar as pred_boxes except all the correct ones\n","        iou_threshold (float): threshold where predicted bboxes is correct\n","        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n","        num_classes (int): number of classes\n","    Returns:\n","        float: mAP value across all classes given a specific IoU threshold\n","    \"\"\"\n","\n","    average_precisions = []\n","\n","    epsilon = 1e-6\n","\n","    for c in range(num_classes):\n","        detections = []\n","        ground_truths = []\n","\n","        for detection in pred_boxes:\n","            if detection[1] == c:\n","                detections.append(detection)\n","\n","        for true_box in true_boxes:\n","            if true_box[1] == c:\n","                ground_truths.append(true_box)\n","\n","        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n","\n","        for key, val in amount_bboxes.items():\n","            amount_bboxes[key] = torch.zeros(val)\n","\n","        detections.sort(key=lambda x: x[2], reverse=True)\n","        TP = torch.zeros((len(detections)))\n","        FP = torch.zeros((len(detections)))\n","        total_true_bboxes = len(ground_truths)\n","\n","        if total_true_bboxes == 0:\n","            continue\n","\n","        for detection_idx, detection in enumerate(detections):\n","        \n","            ground_truth_img = [\n","                bbox for bbox in ground_truths if bbox[0] == detection[0]\n","            ]\n","\n","            num_gts = len(ground_truth_img)\n","            best_iou = 0\n","\n","            for idx, gt in enumerate(ground_truth_img):\n","                iou = intersection_over_union(\n","                    torch.tensor(detection[3:]),\n","                    torch.tensor(gt[3:]),\n","                    box_format=box_format,\n","                )\n","\n","                if iou > best_iou:\n","                    best_iou = iou\n","                    best_gt_idx = idx\n","\n","            if best_iou > iou_threshold:\n","               \n","                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n","             \n","                    TP[detection_idx] = 1\n","                    amount_bboxes[detection[0]][best_gt_idx] = 1\n","                else:\n","                    FP[detection_idx] = 1\n","\n","            else:\n","                FP[detection_idx] = 1\n","\n","        TP_cumsum = torch.cumsum(TP, dim=0)\n","        FP_cumsum = torch.cumsum(FP, dim=0)\n","        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n","        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n","        precisions = torch.cat((torch.tensor([1]), precisions))\n","        recalls = torch.cat((torch.tensor([0]), recalls))\n","      \n","        average_precisions.append(torch.trapz(precisions, recalls))\n","\n","    return sum(average_precisions) / len(average_precisions)\n","\n","\n","\n","class LoadObjectDetectorModule(pl.LightningModule):\n","    def __init__(self, path):\n","        super(LoadObjectDetectorModule, self).__init__()\n","        self.path = path\n","        self.model = self.load_mo()\n","\n","    def load_mo(self):\n","        return torch.load(self.path)\n","\n","    def show(self):\n","        print('{:>35}{:>20}'.format('Ran Epochs :', self.model['epoch']))\n","        print('{:>35}{:>20}'.format('Model Load Status :', 'True' if self.model['model'] else 'False'))\n","        print('{:>35}{:>20}'.format('Optim Load Status :', 'True' if self.model['optim'] else 'False'))\n","\n","    def load(self):\n","        return self.model['model'], self.model['optim'], self.model['epoch']\n","\n","\n","\n","def show(array: (np.ndarray, list, tuple)):\n","    while True:\n","        if isinstance(array, list):\n","            array = np.array(array)\n","        if array.shape[0] == 3:\n","            array = array.reshape((array.shape[1], array.shape[2], array.shape[0]))\n","        array = array.astype(np.uint8)\n","        cv.imshow('show function', array)\n","        cv.waitKey(1)\n","        if keyboard.is_pressed('q'):\n","            break\n","\n","cfg = [\n","    {'name': 'Conv',\n","     'attributes': [3, 32, 3, 1, True, True]},\n","    {'name': 'Conv',\n","     'attributes': [32, 64, 3, 2, True, True]},\n","    {'name': 'ResidualBlock',\n","     'attributes': [64, 4, True]},\n","    {'name': 'C3',\n","     'attributes': [64, 128, True, 2, 0.8]},\n","    {'name': 'Conv',\n","     'attributes': [128, 256, 3, 2, True, True]},\n","    {'name': 'ResidualBlock',\n","     'attributes': [256, 2, True]},\n","    {'name': 'RepConv',\n","     'attributes': [256, 1, 2]},\n","    {'name': 'Conv',\n","     'attributes': [256, 384, 3, 2, True, True]},\n","    {'name': 'Detect',\n","     'attributes': [384, 4]},  # Detect\n","    {'name': 'RepConv',\n","     'attributes': [384, 1, 2]},\n","    {'name': 'Conv',\n","     'attributes': [384, 512, 3, 2, True, True]},\n","    {'name': 'Detect',\n","     'attributes': [512, 4]},  # Detect\n","    {'name': 'RepConv',\n","     'attributes': [512, 1, 2]},\n","    {'name': 'Conv',\n","     'attributes': [512, 768, 3, 2, True, True]},\n","    {'name': 'Detect',\n","     'attributes': [768, 4]},  # Detect\n","]\n","\n","\n","\n","DEVICE = 'cuda:0' if T.cuda.is_available() else 'cpu'\n","\n","\n","class DataReader(Dataset):\n","\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, item, train: bool = True):\n","        x, y = [self.x[item], self.y[item]]\n","        return x, y\n","\n","\n","class DataLoaderLightning(LightningDataModule):\n","    def __init__(self, path, debug: bool = False, nc: int = 4, val_pers=0.3, batch_size: int = 6, prc: float = 0.3,\n","                 img_shape: int = 416, val_perc: float = 0.9):\n","        super(DataLoaderLightning, self).__init__()\n","        with open(path, 'r') as r:\n","            iw = yaml.full_load(r)\n","        self.debug = debug\n","        self.nc = nc\n","        self.val_pers = val_pers\n","        self.batch_size = batch_size\n","        self.img_shape = img_shape\n","        self.val_perc = val_perc\n","        self.debug = debug\n","        self.prc = prc\n","        self.path_train = os.path.join(os.getcwd(), iw['train'])\n","        self.path_valid = os.path.join(os.getcwd(), iw['valid'])\n","        # self.path_train = iw['train']\n","        # self.path_valid = iw['valid']\n","        # self.path_train = os.path.join('E:/Programming/Python/Ai-Projects/ObjectDetectorModule', iw['train'])\n","        # self.path_valid = os.path.join('E:/Programming/Python/Ai-Projects/ObjectDetectorModule', iw['valid'])\n","        self.nc = nc\n","        self.ti = [t for t in os.listdir(self.path_train) if os.path.exists(os.path.join(self.path_train, t)) and\n","                   t.endswith('.jpg')]\n","        self.vi = [v for v in os.listdir(self.path_valid) if os.path.exists(os.path.join(self.path_valid, v)) and\n","                   v.endswith('.jpg')]\n","        self.s = [13, 26, 52]\n","\n","        np.seterr(all='ignore')\n","        self.total = len(self.ti) if not self.debug else int(len(self.ti) / self.prc)\n","        self.x_train, self.y_train = self.__start__(current=self.ti)\n","        self.x_val, self.y_val = self.__start__(current=self.vi, is_val=True)\n","\n","    def __start__(self, current, is_val: bool = False):\n","        xsl, ysl = [], []\n","        path = self.path_valid if is_val else self.path_train\n","        tm = len(current) if not self.debug else int(len(current) * (self.prc if not is_val else self.val_perc))\n","        print(f\"Loading {tm} Samples\")\n","        for item in range(tm):\n","\n","            with open(f'{path}/{current[item][:-4]}.txt', 'r') as r:\n","                sr = r.readline()\n","\n","            bboxes = np.roll(\n","                np.loadtxt(f'{path}/{current[item][:-4]}.txt', delimiter=\" \", ndmin=2, ), 4,\n","                axis=1).tolist() if len(sr) != 0 else []\n","\n","            targets = [torch.zeros(3, S, S, 5 + self.nc) for S in self.s]\n","            for box in bboxes:\n","                x1, y1, w, h, class_label = box\n","                dpa = torch.zeros(self.nc)\n","\n","                dpa[int(class_label)] = 1\n","                class_label = dpa\n","                has_anchor = [False] * 3\n","                for anchor_idx in range(3):\n","                    scale_idx = torch.div((1e-16 + anchor_idx), other=3)\n","                    scale_idx = int(scale_idx)\n","                    anchor_on_scale = anchor_idx % 3\n","                    S = self.s[scale_idx]\n","                    i, j = int(S * y1), int(S * x1)\n","\n","                    anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n","                    if not anchor_taken and not has_anchor[scale_idx]:\n","                        targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n","                        x_cell, y_cell = S * x1 - j, S * y1 - i\n","\n","                        box_coordinates = torch.tensor(\n","                            [x1 * S, y1 * S, h * S, h * S]\n","                        )\n","                        targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n","                        targets[scale_idx][anchor_on_scale, i, j, 5:] = class_label\n","\n","                        has_anchor[scale_idx] = True\n","\n","            img = Image.open(f'{path}/{current[item][:-4]}.jpg')\n","            to_tensor = lambda ten: torch.from_numpy(ten)\n","            tt = lambda xf: xf.type(T.float64)\n","            tn = lambda xr: xr / 255\n","            ts = lambda xs: xs.reshape((self.img_shape, self.img_shape, 3))\n","            data = img.getdata()\n","            image_pixel = list(list(pixel) for pixel in data)\n","            image_rgb = np.array(image_pixel).reshape((self.img_shape, self.img_shape, 3))\n","            image_bgr = image_rgb[:, :, ::-1]\n","            x = to_tensor(image_rgb)\n","            x = ts(tn(tt(x))).permute(2, 1, 0).reshape(3, self.img_shape, self.img_shape)\n","            if DEVICE == 'cuda:0':\n","                x = x.type(T.cuda.FloatTensor)\n","            else:\n","                x = x.type(T.FloatTensor)\n","            xsl.append(x)\n","            ysl.append(tuple(targets))\n","\n","            sys.stdout.write('\\r Moving Data To Ram Or Gpu %{} remaining '.format(\n","                f\"{((item / tm) * 100):.4f}\"))\n","        sys.stdout.write('\\n')\n","        return xsl, ysl\n","\n","    def train_dataloader(self):\n","        data_train = DataReader(self.x_train, self.y_train)\n","        return DataLoader(data_train, batch_size=self.batch_size, num_workers=6)\n","\n","    def val_dataloader(self):\n","        data_val = DataReader(self.x_val, self.y_val)\n","        return DataLoader(data_val, batch_size=self.batch_size, num_workers=6)\n"],"metadata":{"id":"oy3y34o0WgAi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["from loss.py\n"],"metadata":{"id":"imEPURqRWEom"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","\n","DEVICE = 'cuda:0' if torch.cuda.is_available() else \"cpu\"\n","\n","\n","def iou(box1, box2):\n","    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3],\n","    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3],\n","\n","    intersect_x1 = torch.max(b1_x1, b2_x1)\n","    intersect_y1 = torch.max(b1_y1, b2_y1)\n","    intersect_x2 = torch.min(b1_x2, b2_x2)\n","    intersect_y2 = torch.min(b1_y2, b2_y2)\n","\n","    intersect_area = (intersect_x2 - intersect_x1 + 1) * (intersect_y2 - intersect_y1 + 1)\n","\n","    # union area\n","    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n","    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n","\n","    return intersect_area / (b1_area + b2_area - intersect_area + 1e-16)\n","\n","\n","class Loss(pl.LightningModule):\n","    def __init__(self):\n","        super(Loss, self).__init__()\n","        self.ac = 1e-16\n","        self.mse = nn.MSELoss()\n","        self.bce = nn.BCEWithLogitsLoss()\n","        self.ca = nn.CrossEntropyLoss()\n","        self.sigmoid = nn.Sigmoid()\n","        self.to(DEVICE)\n","        self.anc = [\n","            [[10 / 7, 13 / 7], [16 / 7, 30 / 7], [33 / 7, 23 / 7]],\n","            [[30 / 26, 61 / 26, ], [62 / 26, 45 / 26, ], [59 / 26, 119 / 26]],\n","            [[116 / 52, 90 / 52, ], [156 / 52, 198 / 52, ], [373 / 52, 326 / 52],\n","             ]]\n","        self.anc = torch.tensor(self.anc[0] + self.anc[2] + self.anc[2])\n","\n","    def forward(self, x, y, index):\n","        obj = y[..., 0] == 1\n","        no_obj = y[..., 0] == 0\n","        # print(y[obj])\n","        nol = self.bce(\n","            (x[..., 0:1][no_obj]).to(DEVICE), (y[..., 0:1][no_obj].to(DEVICE))\n","        )\n","        # print(self.anc)\n","        # print(self.anc[l * 3:(l * 3) + 3])\n","        anc = self.anc[index:index + 3].reshape(1, 3, 1, 1, 2)\n","        box_pred = torch.cat(\n","            [self.sigmoid(x[..., 1:3]).to(DEVICE), torch.exp(x[..., 3:5]).to(DEVICE) * anc.to(DEVICE)],\n","            dim=-1)\n","        ious = intersection_over_union(box_pred[obj].to(DEVICE), y[..., 1:5][obj].to(DEVICE)).detach()\n","\n","        ol = self.mse(\n","            self.sigmoid(x[..., 0:1][obj]).to(DEVICE), (ious.to(DEVICE) * y[..., 0:1][obj].to(DEVICE))\n","        )\n","\n","        x[..., 1:3] = self.sigmoid(x[..., 1:3])\n","        y[..., 3:5] = torch.log(\n","            (1e-16 + y[..., 3:5])\n","        )\n","\n","        box_loss = self.mse(x[..., 1:5][obj], y[..., 1:5][obj].to(DEVICE))\n","\n","        class_loss = self.bce(\n","            (F.softmax(x[..., 5:][obj], dim=-1).to(DEVICE)), (y[..., 5:][obj].float().to(DEVICE))\n","        )\n","\n","        loss = nol * 1 + box_loss * 1 + ol * 1 + class_loss * 1\n","\n","        return loss\n"],"metadata":{"id":"D_Z4Oi4YV_bP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train Class\n"],"metadata":{"id":"sgph0OTuXWW4"}},{"cell_type":"code","source":["import sys\n","\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","from colorama import Fore\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import BackboneFinetuning, Checkpoint, LearningRateMonitor, ModelCheckpoint, Timer, \\\n","    EarlyStopping\n","import warnings\n","\n","\n","class TrainDi:\n","    def __init__(self):\n","        self.DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","\n","    def run(self):\n","        return NotImplementedError\n","\n","    def load(self, path):\n","        return NotImplementedError\n","\n","    def jit_save(self):\n","        return NotImplementedError\n","\n","\n","class OldMethodTrain(TrainDi):\n","    def __init__(self, nc: int = 4, cfg_path: str = 'cfg.yaml'):\n","        super(OldMethodTrain, self).__init__()\n","        self.nc = nc\n","        self.cfg_path = cfg_path\n","        self.net = ObjectDetectorModule(nc=nc, cfg_path=cfg_path).to(self.DEVICE)\n","        self.dr = DataReader(yaml_path='data/path.yaml', nc=nc, debug=True)\n","        self.loss = Loss()\n","        self.epochs = 100\n","        self.c_epoch = 0\n","        self.optimizer = optim.SGD(self.net.parameters(), lr=1e-4)\n","        # self.lambda_lr = lambda epoch: 0.65 ** epoch\n","        self.scheduler = torch.optim.lr_scheduler.ConstantLR(self.optimizer, factor=0.1, total_iters=2)\n","        self.grad_scalar = torch.cuda.amp.GradScaler()\n","\n","    def white_space(self):\n","        # for idx in range(self.dr.total):\n","        x, y = self.dr.__getitem__(0)\n","        print('-' * 20)\n","\n","        c = torch.tensor(y[0])\n","        print(c.shape, '\\n')\n","\n","        c = torch.tensor(y[1])\n","        print(c.shape, '\\n')\n","\n","        c = torch.tensor(y[2])\n","        print(c.shape, '\\n')\n","        print('-' * 20)\n","\n","    def run(self):\n","        while self.c_epoch <= self.epochs:\n","            fr = True\n","            for idx in range(self.dr.total):\n","                x, y = self.dr.__getitem__(idx)\n","                self.optimizer.zero_grad()\n","\n","                x = x.to(self.DEVICE)\n","\n","                tvm = True\n","\n","                with torch.cuda.amp.autocast():\n","                    x = self.net.forward(x)\n","                    y = [torch.unsqueeze(v, 0) for v in y]\n","\n","                    loss = (self.loss(x=x[0], y=y[2], index=0)\n","                            + self.loss(x=x[1], y=y[1], index=3)\n","                            + self.loss(x=x[2], y=y[0], index=6))\n","\n","                acc = None\n","                if fr:\n","                    fr = False\n","                    sys.stdout.write('\\r {}{:>20}/{:<15}{:>15}{:>15}{:>10}'.format(Fore.YELLOW, 'C Ep|', 'Ep|',\n","\n","                                                                                   'class_loss|',\n","                                                                                   'accuracy|',\n","                                                                                   'lr|'))\n","                    print('/n')\n","                if idx != 0:\n","                    sys.stdout.write(\n","                        '\\r {}{:>20}/{:<15}{:>15}{:>15}{:>10}'.format(Fore.YELLOW, f\"{self.c_epoch}\", f\"{self.epochs}\",\n","                                                                      f\"{loss:.5f}|\",\n","                                                                      f\"{None}|\",\n","                                                                      f\"{self.scheduler.get_lr()[0]}\"))\n","                    sys.stdout.flush()\n","                self.grad_scalar.scale(loss).backward()\n","                self.grad_scalar.step(optimizer=self.optimizer)\n","                self.grad_scalar.update()\n","                if idx % 500 == 0:\n","                    model_ckpt = {\n","                        'model': self.net.state_dict(),\n","                        'optim': self.optimizer.state_dict(),\n","                        'optim_scheduler': self.scheduler.state_dict(),\n","                        'epoch': self.c_epoch\n","                    }\n","                    torch.save(model_ckpt, 'model_grad.pt')\n","            # self.scheduler.step()\n","            print('\\n')\n","            self.c_epoch += 1\n","            # if self.c_epoch <= self.epochs:\n","            #     self.jit_save()\n","\n","    def jit_save(self):\n","        model_ckpt = {\n","            'model': self.net.state_dict(),\n","            'optim': self.optimizer.state_dict(),\n","            'optim_scheduler': self.scheduler.state_dict(),\n","            'epoch': self.c_epoch\n","        }\n","        di = torch.randn((1, 3, 416, 416)).to(self.DEVICE)\n","        j = torch.jit.trace(self.net, di, check_trace=False)\n","        s = torch.jit.script(j)\n","        torch.jit.save(s, 'model-jit.pt',\n","                       model_ckpt\n","                       )\n","\n","    def load(self, path):\n","        lod = LoadObjectDetectorModule('model.pt')\n","        m, o, e = lod.load()\n","        self.net.load_state_dict(m)\n","        self.optimizer.load_state_dict(o)\n","        self.c_epoch = e\n","        lod.show()\n","        print('{:>35}{:>20}'.format('Status :', \" Done *\" if m else 'Error !'))\n"],"metadata":{"id":"dgj9ukpwXXoe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main Module creator:"],"metadata":{"id":"yyayAiPEYD37"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import yaml\n","from colorama import Fore\n","\n","import pytorch_lightning as pl\n","from torchmetrics.functional import accuracy\n","\n","DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","\n","\n","class ObjectDetectorModule(pl.LightningModule):\n","    def __init__(self, nc: int = 4, cfg=None):\n","        super(ObjectDetectorModule, self).__init__()\n","        \"\"\"\n","        Nc : Number of Classes\n","        cfg : pass dict version of configs to create module\n","        \"\"\"\n","        if cfg is None:\n","            cfg = {}\n","        self.nc = nc\n","        if isinstance(cfg, str):\n","            with open(cfg, 'r') as r:\n","                self.cfg = yaml.full_load(r)\n","        else:\n","            self.cfg = cfg\n","\n","        self.layers = self.layer_creator()\n","        self.fr = False\n","\n","        self.to(DEVICE)\n","        self.loss = Loss()\n","        self.save_hyperparameters()\n","\n","    def layer_creator(self):\n","        layers = nn.ModuleList()\n","        for cfg in self.cfg:\n","            at = cfg['attributes']\n","            if cfg['name'] == 'Conv':\n","                layers.append(Conv(c1=at[0], c2=at[1], kernel_size=at[2], stride=at[3], act=at[4], batch=at[5],\n","                                   padding=1 if at[2] == 3 else 0)).to(DEVICE)\n","            if cfg['name'] == 'ResidualBlock':\n","                layers.append(ResidualBlock(c1=at[0], n=at[1], use_residual=at[2]).to(DEVICE))\n","            if cfg['name'] == 'Detect':\n","                layers.append(Detect(c1=at[0], nc=at[1]).to(DEVICE))\n","            if cfg['name'] == 'UpSample':\n","                layers.appendnn.Upsample(scale_factor=at[0]).to(DEVICE)\n","            if cfg['name'] == 'C3':\n","                layers.append(C3(c1=at[0], c2=at[1], shortcut=at[2], n=at[3], e=at[4]).to(DEVICE))\n","            if cfg['name'] == 'Neck':\n","                layers.append(Neck(c1=at[0], c2=at[1], shortcut=at[2], e=at[3], ).to(DEVICE))\n","            if cfg['name'] == 'C4P':\n","                layers.append(C4P(c=at[0], e=at[1], n=at[2], ct=at[3]).to(DEVICE))\n","            if cfg['name'] == 'MP':\n","                layers.append(MP())\n","            if cfg['name'] == 'UC1':\n","                layers.append(UC1(c1=at[0], c2=at[1], e=at[2], dim=at[3]))\n","            if cfg['name'] == 'CV1':\n","                layers.append(CV1(c1=at[0], c2=at[1], e=at[2], n=at[3], shortcut=at[4]))\n","            if cfg['name'] == 'RepConv':\n","                layers.append(RepConv(c=at[0], e=at[1], n=at[2]))\n","            if cfg['name'] == 'ConvSc':\n","                layers.append(ConvSc(c=at[0], n=at[1]))\n","        return nn.Sequential(*layers)\n","\n","    # @torch.jit.script\n","    def size(self):\n","\n","        ps = 0\n","        for name, pr in self.layers.named_parameters():\n","            sz = (pr.numel() * torch.finfo(pr.data.dtype).bits) / (1024 * 10000)\n","            ps += sz\n","            print(\"| {:<30} | {:<25} |\".format(name, f\"{sz} Mb\"))\n","        print('-' * 50)\n","        print(f' TOTAL SIZE  :  {ps} MB')\n","\n","    def forward(self, x):\n","        route = []\n","        bpm = None\n","        dtt = []\n","        vi = 0\n","\n","        for index, layer in enumerate(self.layers):\n","            # print(x.shape, '\\n')\n","            if not isinstance(layer, (nn.Upsample, Detect, MP)):\n","                if self.fr:\n","                    print('{}{:>50} {:>20}   {:>20}'.format(Fore.BLUE,\n","                                                            f'Shape Before RunTime {[l for l in x.shape]}', \"[!]\",\n","                                                            f\"Layer : {vi}\"))\n","                    print('{:>50} {:>20}   {:>20}'.format(f'Pass To {type(layer).__name__}', \"[->]\",\n","                                                          f\"Layer : {vi}\"))\n","                x = layer(x)\n","                if self.fr:\n","                    print('{:>50} {:>20}   {:>20}'.format(f'Shape After  RunTime {[l for l in x.shape]}', \"[*]\",\n","                                                          f\"Layer : {vi}\"))\n","                    print('-' * 100)\n","\n","            if isinstance(layer, MP):\n","                route = layer(x, route)\n","                if self.fr:\n","                    print('{:>50}  {:>20}'.format(f'NOTICE ! add To Route shape {[v for v in x.shape]}',\n","                                                  '! WARNING !'))\n","                    print('-' * 100)\n","            if isinstance(layer, Detect):\n","                if self.fr:\n","                    print('{:>50} {:>20}   {:>20}'.format('Detect Layer on RunTime', '[!]', f\"Layer : {vi}\",\n","                                                          ))\n","                    print('{:>20}'.format('Before Detect Layer : {}'.format(x.shape)))\n","                f = layer(x)\n","                dtt.append(f)\n","                if self.fr:\n","                    print(\n","                        '{:>50} {:>20}   {:>20}'.format(f'Detect Layer Done shape {[v for v in f.shape]}]', '[*]',\n","                                                        f\"Layer : {vi}\"))\n","                    print('-' * 100)\n","            if isinstance(layer, nn.Upsample):\n","                x = layer(x)\n","                if len(route[-1].shape) == 3:\n","                    c = torch.unsqueeze(route[-1], dim=0)\n","                else:\n","                    c = route[-1]\n","                if self.fr:\n","                    print(\"\\n{:>100}\\n\".format(f'Trying to pair x : {x.shape} to residual {route[-1].shape}',\n","                                               ))\n","\n","                if self.fr:\n","                    print('{:>50} {:>20}   {:>20}\\n'.format(f'UpSample Layer {[v for v in x.shape]}]', '[!]',\n","                                                            f\"Layer : {vi}\"))\n","                    print('-' * 100)\n","\n","                x = torch.concat((c, x), dim=1)\n","                if isinstance(route, list):\n","                    route = route.pop(0)\n","\n","            vi += 1\n","        if len(dtt) != 0:\n","            cv = dtt\n","        else:\n","            cv = x\n","        if self.fr:\n","            self.fr = False\n","        return cv\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.SGD(self.parameters(), lr=1e-4)\n","        lr_lambda = lambda epoch: 0.85 * epoch\n","        lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n","            optimizer, lr_lambda\n","        )\n","        return [optimizer], [lr_scheduler]\n","\n","    def training_step(self, batch, batch_index):\n","        x, y = batch\n","        x_ = self(x)\n","        loss = (self.loss.forward(x_[0], y[2], 0) + self.loss.forward(x_[1], y[1], 1) + self.loss.forward(x_[2], y[0],\n","                                                                                                          2))\n","        # acc_train_v1 = accuracy(x_[0], target=y[2].int())\n","        # acc_train_v2 = accuracy(x_[1], target=y[1].int())\n","        # acc_train_v3 = accuracy(x_[2], target=y[0].int())\n","        # self.log('train_acc', torch.tensor((acc_train_v1, acc_train_v2, acc_train_v3)), prog_bar=True, on_step=True,\n","        #          on_epoch=True)\n","        self.log('train_loss', loss, prog_bar=True, on_step=True,\n","                 on_epoch=True)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, batch, batch_index):\n","        x, y = batch\n","        x_ = self(x)\n","\n","        loss = (self.loss.forward(x_[0], y[2], 0) + self.loss.forward(x_[1], y[1], 1) + self.loss.forward(x_[2], y[0],\n","                                                                                                          2))\n","        # acc_val_v1 = accuracy(x_[0], target=y[2].int())\n","        # acc_val_v2 = accuracy(x_[1], target=y[1].int())\n","        # acc_val_v3 = accuracy(x_[2], target=y[0].int())\n","        # self.log('val_acc', torch.tensor((acc_val_v1, acc_val_v2, acc_val_v3)), prog_bar=True, on_step=True,\n","        #          on_epoch=True)\n","        self.log('val_loss', loss, prog_bar=True, on_step=True,\n","                 on_epoch=True)\n","        return {\"loss\": loss}\n"],"metadata":{"id":"X3KNxMVgYC7f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["main training loop from train.py"],"metadata":{"id":"qd3epuJZYX_p"}},{"cell_type":"code","source":["\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import BackboneFinetuning, Checkpoint, LearningRateMonitor, ModelCheckpoint, Timer, \\\n","    EarlyStopping\n","\n","from pytorch_lightning.callbacks import ModelSummary\n","\n","cfg_list = cfg\n","\n","class LightningTrain:\n","    def __init__(self, nc: int = 4, cfg: [str, list] = cfg_list):\n","        super(LightningTrain, self).__init__()\n","        self.nc = nc\n","        self.cfg = cfg\n","        self.net = ObjectDetectorModule(cfg=self.cfg, nc=self.nc)\n","\n","    def train(self, time: str = None):\n","        self.net.prepare_data()\n","\n","        backbone_fine = BackboneFinetuning()\n","        checkpoint = Checkpoint()\n","        model_summery = ModelSummary(max_depth=10)\n","        model_checkpoint = ModelCheckpoint(dirpath='model/saves/', save_top_k=10, monitor='train_loss')\n","        lr_monitor = LearningRateMonitor(logging_interval='step')\n","        early_stopping = EarlyStopping('val_loss')\n","        timer = Timer(duration='01:00:00:00' if time is None else time)\n","        trainer = pl.Trainer(devices=1, accelerator='gpu', min_epochs=50, max_epochs=50000,\n","                             callbacks=[model_summery, model_checkpoint, checkpoint, lr_monitor, early_stopping, timer])\n","        data_loader_lightning = DataLoaderLightning(path='data/path.yaml', debug=True, val_pers=0.3, nc=4, prc=0.2,\n","                                                    batch_size=1)\n","        dataloader_train = data_loader_lightning.train_dataloader()\n","        dataloader_validation = data_loader_lightning.val_dataloader()\n","        trainer.fit(self.net, train_dataloaders=dataloader_train, val_dataloaders=dataloader_validation)\n","        self.net.prepare_data()\n","\n","\n","if __name__ == \"__main__\":\n","    train_class = LightningTrain()\n","    train_class.train()\n"],"metadata":{"id":"S2MWrqhbYTXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"scVdjDbBYltI"},"execution_count":null,"outputs":[]}]}